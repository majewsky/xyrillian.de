Laut Wiktionary:

> \[**Text** ist eine\] mÃ¼ndliche oder schriftliche Folge von SÃ¤tzen, die miteinander syntaktisch und semantisch verbunden sind (KohÃ¤renz, KohÃ¤sion), eine abgeschlossene Einheit bilden (Kompletion) und eine bestimmte kommunikative Funktion (Textfunktion) erfÃ¼llen.
> 
> \[Von\] lateinisch _textus_ fÃ¼r "Inhalt" oder "Gewebe der Rede", "Text".

- zur Definition
    - Wiktionary geht vom linguistischen Blickwinkel aus
    - in der Informatik: Zeichenketten (oder synonym "Zeichenfolgen"), in Programmiersprachen meist als [String](https://de.wikipedia.org/wiki/Zeichenkette ) bezeichnet

- Problem: Computer kÃ¶nnen nur Zahlen! Wie bilden wir Zeichenketten als Zahlenfolgen ab?
    - Idee 1: jedes Zeichen als eine Zahl einer bestimmten GrÃ¶ÃŸe, z.B. 1 Byte oder 2 Byte (_fixed-length code_)
        - primitives Beispiel: alle Buchstaben des Alphabets durch ihre Position darstellen, z.B. "hallo" -> "08 01 12 12 15"
    - Idee 2: hÃ¤ufige Zeichen mit kurzen Bytefolgen darstellen, seltene Zeichen mit lÃ¤ngeren Bytefolgen (_variable-length code_, siehe [Entropiekodierung](https://de.wikipedia.org/wiki/Entropiekodierung))

- Beispiel: [Morse-Code](https://de.wikipedia.org/wiki/Morsezeichen)
    - variable LÃ¤nge: z.B. "e" ist am hÃ¤ufigsten und deswegen nur 1 Ton kurz, "q" ist sehr selten und deswegen 4 TÃ¶ne lang
    - Kodiertabelle enthÃ¤lt nicht nur Buchstaben und Ziffern, sondern auch Sonderzeichen (Punkt, Komma, etc.) und Spezialzeichen wie "Spruchende" oder "Fehler, Wiederholung ab letztem vollstÃ¤ndigem Wort"

- in der frÃ¼hen Informatik (bis in die 1990er Jahre): **Codepages** (Zeichentabellen)
    - Codes mit fester LÃ¤nge von meist 1 Byte (7 oder 8 Bit) pro Zeichen
    - Beispiel mit 7 Bit: [ASCII](https://de.wikipedia.org/wiki/ASCII ), unter Linux siehe `man ascii` ([RFC 20](https://datatracker.ietf.org/doc/html/rfc20 ))
    - Beispiel mit 8 Bit: [Codepage 437](https://de.wikipedia.org/wiki/Codepage_437 )
    - Standardisierung als [ISO/IEC 8859](https://en.wikipedia.org/wiki/ISO/IEC_8859 )
    - Problem: 8 Bit (256 Zeichen) sind zu wenig fÃ¼r alle in europÃ¤ischen Sprachen verwendeten Zeichen, insb. wegen [diakritischer Zeichen](https://de.wikipedia.org/wiki/Diakritisches_Zeichen ) -> verschiedene Codepages fÃ¼r verschiedene Sprachen -> [Mojibake](https://de.wikipedia.org/wiki/Zeichensalat )
    - spÃ¤testens mit zunehmend globaler Kommunikation im Internetzeitalter musste eine bessere LÃ¶sung her

- [Unicode](https://de.wikipedia.org/wiki/Unicode )
    - keine Textkodierung im engeren Sinne, sondern erstmal nur eine durchnummerierte Liste aller mÃ¶glichen Zeichen (die Nummer zu einem Zeichen heiÃŸt **Codepunkt**)
    - Anspruch: wenn ein Zeichen in tatsÃ¤chlichen Textdokumenten verwendet wird oder wurde, gehÃ¶rt es in Unicode (von Buchstaben Ã¼ber Redigierungssymbole mittelalterlicher Typografen bis zu Hieroglyphen und Keilschrift)
    - GrÃ¶ÃŸe: 17 Ebenen (_Planes_) zu je 65536 Codepunkten = 1.114.112 Codepunkte; davon sind 2048 Codepunkte aus technischen GrÃ¼nden (fÃ¼r die Kodierung von Surrogatpaaren) unbelegbar, somit maximal mÃ¶glich 1.112.064 Codepunkte

- Ebenen in Unicode
    - Ebene 0: **Basic Multilingual Plane** mit allen zeitgenÃ¶ssischen und weitverbreiteten Schriftsystemen ([Ãœbersichtskarte](https://commons.wikimedia.org/wiki/File:Roadmap_to_Unicode_BMP_multilingual.svg ))
    - Ebene 1: **Supplementary Multilingual Plane** mit historischen Schriftsystemen und ObskuritÃ¤ten wie Domino/Mahjongg-Steinen und ğŸ˜ Emoji ğŸ˜
    - Ebene 2: **Supplementary Ideographic Plane** mit selten benutzten CJK-Schriftzeichen
    - Ebene 3-13: noch frei
    - Ebene 14: **Supplementary Special-purpose Plane** mit Steuerzeichen zur Selektion alternativer Schriftzeichenformen
    - Ebene 15/16: fÃ¼r private Verwendung reserviert

- Kodierungen fÃ¼r Unicode mit fixer LÃ¤nge
    - UCS-2: eine 16-Bit-Zahl pro Zeichen -> kann nur die BMP kodieren (UCS-2 stammt aus der Zeit, bevor Unicode mehrere Planes hatte)
    - UCS-4/UTF-32: eine 32-Bit-Zahl pro Zeichen -> extrem verschwenderisch

- Kodierungen fÃ¼r Unicode mit variabler LÃ¤nge
    - UTF-16: BMP-Zeichen als eine 16-Bit-Zahl, andere Zeichen als zwei 16-Bit-Zahlen -> Probleme mit Endianness
    - [UTF-8](https://de.wikipedia.org/wiki/UTF-8 ): jedes ASCII-Zeichen als ein Byte, alle anderen Zeichen als eine Folge von 2-5 Bytes (unter Linux siehe `man utf-8`)
    - UTF-8 ist spektakulÃ¤r: sehr kompakt, selbstsynchronisierend, einfach zu implementieren (auch in Hardware), sortierungserhaltend, ASCII-abwÃ¤rtskompatibel, Nicht-ASCII-Zeichen enthalten niemals ASCII-Bytes; und wurde buchstÃ¤blich in einem Abend von Ken Thompson und Rob Pike auf einer Serviette entworfen

- Probleme von Unicode
    - Anspruch: jeder bestehende Kodierungsstandard soll Zeichen fÃ¼r Zeichen in Unicode abbildbar sein -> dadurch unnÃ¶tig viele Codepunkte insb. fÃ¼r diakritische Zeichen und Probleme mit Normalisierung
    - allgemeiner: Was ist eigentlich ein Zeichen im Sinne von "ein Codepunkt"? (mehr dazu in der nÃ¤chsten Folge) -> Unicode Ã¼bernimmt hier oftmals teils kontroverse Klassifikationen aus nationalen Standards z.B. fÃ¼r indische und thailÃ¤ndische Schriften
    - am signifikantesten hier: [Han-Vereinheitlichung](https://de.wikipedia.org/wiki/Han-Vereinheitlichung ) ([Beispiel](https://commons.wikimedia.org/wiki/File:Source_Han_Sans_Version_Difference.svg ))

FÃ¼r die historische Herleitung von Schriftkodierung empfehlen wir wieder den groÃŸartigen Podcast [Request for Comments](https://requestforcomments.de/ ). Diesmal [die Folge Ã¼ber RFC 20 ASCII](https://requestforcomments.de/archives/400 ).

Das nÃ¤chste Mal geht es dann um TÍ‘Í‹Í¥Í˜ÌªÍ™ÌªÌ»Ì¹Ì©Ì Í”eÍ¦Í¬Ì¨Ì¥Í”ÌÌ˜xÌ’ÌŠÍ†Ì¨ÌœÌ©ÌœÍ™Ì¦Ì»Ì—Ì³tÌ“Í¥ÍÍ£ÍÌ¯Ì³dÌÍ›ÍœÍ”Ì±Ì—Ì¯ÌªÌ­Í…aÍ®Í’Í­ÌµÍ•Ì¯Í•Ì»ÌœrÌ‘Ì‹ÌÍ„Í˜ÌœÍšÍšÌ¯ÍÍ“sÌ†Ì¿Í¡Ì¥Ì¯Ì Ì¬tÍƒÍ’Í‘ÍÍ¢Ì«Ì±ÌºÍ‰Ì±eÌ…Ì¸Í–Ì®Ì™ÌºÌ Ì—Í…Ì¬lÍªÍ‹Í¤ÍœÌÍ‰ÍšlÌ‰Í‘ÌµÌ¦ÌªÍ”ÍˆuÌ”Ì´ÌÌ²Ì Ì³Ì–Ì˜ÍšnÌÌ†ÍŠÌˆÍ¢Í™Ì¹gÌÌ¨ÍÌ£ÌÌ£Í‡Ì¯Ì®Ì .
